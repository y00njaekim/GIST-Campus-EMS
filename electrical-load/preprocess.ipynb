{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['학사 일보.gcf_2022-08-14_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-21_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-19_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-02_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-16_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-23_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-27_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-28_23-59.xls',\n",
       " '.DS_Store',\n",
       " '학사 일보.gcf_2022-07-09_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-12_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-06_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-31_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-25_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-04_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-10_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-01_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-15_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-20_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-17_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-18_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-03_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-22_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-29_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-26_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-07_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-08_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-13_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-24_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-30_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-11_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-05_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-23_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-16_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-19_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-02_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-21_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-14_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-10_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-04_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-25_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-31_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-06_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-09_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-12_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-28_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-27_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-22_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-18_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-03_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-17_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-20_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-15_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-01_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-05_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-11_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-30_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-24_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-08_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-13_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-07_23-59.xls',\n",
       " '학사 일보.gcf_2022-07-26_23-59.xls',\n",
       " '학사 일보.gcf_2022-08-29_23-59.xls']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "file_master_dir = './data-master/'\n",
    "file_master_list = [f for f in os.listdir(file_master_dir) if os.path.isfile(os.path.join(file_master_dir, f))]\n",
    "file_master_list\n",
    "\n",
    "file_under_dir = './data-under/'\n",
    "file_under_list = [f for f in os.listdir(file_under_dir) if os.path.isfile(os.path.join(file_under_dir, f))]\n",
    "file_under_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_of_week(date_str):\n",
    "    return datetime.datetime.strptime(date_str, '%Y-%m-%d').strftime('%A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path, target):\n",
    "    import re\n",
    "    original_data = pd.read_excel(file_path, header=None)\n",
    "\n",
    "    # 새로운 데이터프레임을 만들고, A11부터 A34까지의 값을 'time' 헤더로 넣어줍니다\n",
    "    new_data = pd.DataFrame()\n",
    "    new_data[\"time\"] = original_data.iloc[10:34, 0]\n",
    "\n",
    "    # 나머지 헤더와 범위에 대한 정보를 정리합니다\n",
    "    columns_info = {}\n",
    "    \n",
    "    if target=='master':\n",
    "        columns_info = {\n",
    "            # \"SV-2\": (10, 7),\n",
    "            # \"SV-5\": (10, 18),\n",
    "            # \"SV-6\": (10, 29),\n",
    "            # \"HV-M1\": (10, 37),\n",
    "            # \"HV-M2\": (10, 42),\n",
    "            # \"HV-NM\": (10, 47),\n",
    "            # \"HV-EM\": (10, 52),\n",
    "            \"중앙P/P\": (10, 57),\n",
    "            \"전기전자컴퓨터공학동\": (10, 62),\n",
    "            \"신소재공학\": (10, 67),\n",
    "            \"생명과학동\": (10, 72),\n",
    "            \"기계공학동\": (10, 77),\n",
    "            \"LG도서관\": (10, 82),\n",
    "            \"창업B동\": (10, 87),\n",
    "            \"금호관\": (10, 92),\n",
    "            \"냉각수순환펌프1,2,3\": (10, 97),\n",
    "            \"냉각수순환펌프4,5,6\": (10, 102),\n",
    "            \"기혼자아파트E동\": (10, 107),\n",
    "            \"기숙사9동\": (10, 112),\n",
    "            \"고등광/극초단\": (10, 117),\n",
    "            \"신소재공학동(E)\": (10, 122),\n",
    "            \"전기전자컴퓨터공학동(E)\": (10, 127),\n",
    "            \"생명과학동(E)\": (10, 132),\n",
    "            \"기계공학동(E)\": (10, 137),\n",
    "            \"LG도서관(E)\": (10, 142),\n",
    "            \"중앙P/P(E)\": (10, 147),\n",
    "            \"고등광연구소(E)\": (10, 152),\n",
    "        }\n",
    "    elif target=='under':\n",
    "        columns_info = {\n",
    "            # \"SV-2\": (10, 7),\n",
    "            # \"SV-5\": (10, 18),\n",
    "            # \"SV-6\": (10, 29),\n",
    "            # \"SV-7\": (10, 40),\n",
    "            # \"HV-NM1\": (10, 48),\n",
    "            # \"HV-NM2\": (10, 53),\n",
    "            # \"고압콘덴샤\": (10, 58),\n",
    "            \"신재생에너지동\": (10, 63),\n",
    "            \"대학B동\": (10, 68),\n",
    "            \"대학기숙사A동\": (10, 73),\n",
    "            \"제2학생회관\": (10, 78),\n",
    "            \"학사P/P\": (10, 83),\n",
    "            \"교원아파트\": (10, 88),\n",
    "            \"대학C동\": (10, 93),\n",
    "            \"중앙연구기기센터\": (10, 98),\n",
    "            \"대학A동\": (10, 103),\n",
    "            \"다산빌딩\": (10, 108),\n",
    "            \"산학협력연구동\": (10, 113),\n",
    "            \"신재생에너지동(E)\": (10, 118),\n",
    "            \"대학B동(E)\": (10, 123),\n",
    "            \"대학기숙사A동(E)\": (10, 128),\n",
    "            \"학사P/P(E)\": (10, 133),\n",
    "            \"제2학생회관(E)\": (10, 138),\n",
    "            \"교원아파트(E)\": (10, 143),\n",
    "            \"대학C동(E)\": (10, 148),\n",
    "            \"중앙연구기기센터(E)\": (10, 153),\n",
    "            \"대학A동(E)\": (10, 158),\n",
    "            \"다산빌딩(E)\": (10, 163),\n",
    "            \"산학협력연구동(E)\": (10, 168),\n",
    "        }\n",
    "\n",
    "    # 위에서 정리한 정보를 바탕으로 새로운 데이터프레임에 각 열을 추가합니다\n",
    "    for column_name, (row_start, col_idx) in columns_info.items():\n",
    "        original_data.iloc[row_start:row_start + 24, col_idx] = round(original_data.iloc[row_start:row_start + 24, col_idx].astype(float), 1)\n",
    "        new_data[column_name] = original_data.iloc[row_start:row_start + 24, col_idx]\n",
    "\n",
    "    # 파일 제목에서 날짜 형식의 값을 뽑아냅니다\n",
    "    date_pattern = r\"\\d{4}-\\d{2}-\\d{2}\"\n",
    "    date_match = re.search(date_pattern, file_path)\n",
    "    if date_match:\n",
    "        date_value = date_match.group(0)\n",
    "    else:\n",
    "        date_value = None\n",
    "\n",
    "    # 'day' 열을 추가하고 날짜 값을 모든 행에 동일하게 적용합니다\n",
    "    new_data[\"day\"] = date_value\n",
    "\n",
    "    # 'time' 열의 값에서 '시' 문자를 제거하고 숫자로 변환합니다\n",
    "    new_data[\"time\"] = new_data[\"time\"].str.replace(\"시\", \"\").astype(int)\n",
    "\n",
    "    # day 열을 가장 왼쪽으로 이동합니다\n",
    "    new_data = new_data[[\"day\"] + [col for col in new_data.columns if col != \"day\"]]\n",
    "\n",
    "    # 최종 결과를 CSV 형태로 저장합니다\n",
    "    csv_output_path =  \"./\" + os.path.dirname(file_path) + \"/processed/\" + os.path.basename(file_path)[:-4] + '_filtered.csv'\n",
    "    new_data.to_csv(csv_output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in file_master_list:\n",
    "    if file_name.startswith('.'):\n",
    "        continue\n",
    "    preprocess(os.path.join(file_master_dir, file_name), 'master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in file_under_list:\n",
    "    if file_name.startswith('.'):\n",
    "        continue\n",
    "    preprocess(os.path.join(file_under_dir, file_name), 'under')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = './data-master/processed/'\n",
    "file_list = os.listdir(file_dir)\n",
    "file_list\n",
    "\n",
    "master_dfs = [pd.read_csv(os.path.join(file_dir, file)) for file in file_list if not file.startswith('.')]\n",
    "for df in master_dfs:\n",
    "    for col in df.columns:\n",
    "        if col not in [\"day\", \"time\"]:\n",
    "            df.rename(columns={col: col + \"_석사\"}, inplace=True)\n",
    "            \n",
    "master_combined = pd.concat(master_dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "file_dir = './data-under/processed/'\n",
    "file_list = os.listdir(file_dir)\n",
    "file_list\n",
    "under_dfs = [pd.read_csv(os.path.join(file_dir, file)) for file in file_list if not file.startswith('.')]\n",
    "for df in under_dfs:\n",
    "    for col in df.columns:\n",
    "        if col not in [\"day\", \"time\"]:\n",
    "            df.rename(columns={col: col + \"_학사\"}, inplace=True)\n",
    "\n",
    "# Concatenate the \"학사 일보*\" files\n",
    "under_combined = pd.concat(under_dfs, ignore_index=True)\n",
    "\n",
    "# Merge the data based on 'day' and 'time'\n",
    "merged_df = pd.merge(master_combined, under_combined, on=['day', 'time'], how='outer')\n",
    "sorted_df = merged_df.sort_values(by=['day', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply the function to the 'day' column to create a new 'weekday' column\n",
    "sorted_df['weekday'] = sorted_df['day'].apply(get_day_of_week)\n",
    "\n",
    "# Rearrange the columns to place 'weekday' next to 'day'\n",
    "cols = sorted_df.columns.tolist()\n",
    "cols = cols[:2] + [cols[-1]] + cols[2:-1]\n",
    "sorted_df = sorted_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gd/9_33qhbn7jsdj8d4mrgqgq_80000gn/T/ipykernel_3265/1910627678.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  relevant_cols.rename(columns={\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.read_csv(\"../solar-power/merged_result.csv\")\n",
    "\n",
    "relevant_cols = result_df[['day', 'time', '1시간기온', '1시간강수량', '일최고기온', '일최저기온']]\n",
    "\n",
    "relevant_cols.rename(columns={\n",
    "    '1시간기온': '1시간기온',\n",
    "    '1시간강수량': '1시간강수량',\n",
    "    '일최고기온': '일최고기온',\n",
    "    '일최저기온': '일최저기온'\n",
    "}, inplace=True)\n",
    "\n",
    "merged_with_relevant = pd.merge(sorted_df, relevant_cols, on=['day', 'time'], how='left')\n",
    "\n",
    "final_cols = merged_with_relevant.columns.tolist()\n",
    "cols_order = final_cols[:3] + final_cols[-4:] + final_cols[3:-4]\n",
    "final_df = merged_with_relevant[cols_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the merged dataframe to a CSV file\n",
    "output_path = \"./merged_data.csv\"\n",
    "final_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gist-campus-ems-ntfQ-Uq6-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
